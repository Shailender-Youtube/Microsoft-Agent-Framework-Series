import asyncio
import os
from datetime import datetime
from dotenv import load_dotenv
from typing import Callable, Awaitable

from agent_framework.azure import AzureOpenAIChatClient
from agent_framework import (
    AgentRunContext,
    FunctionInvocationContext,
    ChatContext,
    agent_middleware,
    function_middleware,
    chat_middleware
)

load_dotenv('.env03')

ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
DEPLOYMENT = "gpt-4o"
API_VERSION = "2024-10-21"


# ============================================================================
# MIDDLEWARE 1: TIMING (Agent Middleware)
# ============================================================================

@agent_middleware
async def timing_middleware(
    context: AgentRunContext,
    next: Callable[[AgentRunContext], Awaitable[None]],
) -> None:
    """Tracks execution time for entire agent run."""
    start_time = datetime.now()
    
    print(f"\n‚è±Ô∏è  [TIMING] Started at {start_time.strftime('%H:%M:%S')}")
    
    # Execute agent
    await next(context)
    
    # Calculate duration
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    print(f"‚è±Ô∏è  [TIMING] Completed in {duration:.2f} seconds")


# ============================================================================
# MIDDLEWARE 2: SECURITY (Agent Middleware)
# ============================================================================

@agent_middleware
async def security_middleware(
    context: AgentRunContext,
    next: Callable[[AgentRunContext], Awaitable[None]],
) -> None:
    """Blocks requests containing sensitive keywords."""
    
    # Check the last message for blocked content
    if context.messages:
        last_message = context.messages[-1]
        if hasattr(last_message, 'contents'):
            for content in last_message.contents:
                if hasattr(content, 'text'):
                    text = str(content.text).lower()
                    
                    # List of blocked keywords
                    blocked_keywords = ["password", "secret", "hack", "exploit", "bypass"]
                    
                    for keyword in blocked_keywords:
                        if keyword in text:
                            print(f"\nüö´ [SECURITY] Request BLOCKED! Detected: '{keyword}'")
                            print(f"üö´ [SECURITY] This request contains sensitive content and cannot be processed.")
                            context.terminate = True
                            return
    
    # If safe, continue
    await next(context)


# ============================================================================
# MIDDLEWARE 3: FUNCTION LOGGER (Function Middleware)
# ============================================================================

@function_middleware
async def function_logger_middleware(
    context: FunctionInvocationContext,
    next: Callable[[FunctionInvocationContext], Awaitable[None]],
) -> None:
    """Logs every function/tool call with arguments and results."""
    
    print(f"\nüîß [FUNCTION] Calling tool: {context.function.name}")
    print(f"üîß [FUNCTION] Arguments: {context.arguments}")
    
    # Execute the function
    await next(context)
    
    # Log the result
    print(f"üîß [FUNCTION] Result: {context.result}")


# ============================================================================
# MIDDLEWARE 4: TOKEN COUNTER (Chat Middleware)
# ============================================================================

@chat_middleware
async def token_counter_middleware(
    context: ChatContext,
    next: Callable[[ChatContext], Awaitable[None]],
) -> None:
    """Estimates and logs token usage for AI calls."""
    
    # Estimate input tokens (rough: 1 token ‚âà 4 characters)
    total_chars = sum(len(str(msg)) for msg in context.messages)
    estimated_input_tokens = total_chars // 4
    
    print(f"\nü§ñ [AI CALL] Sending request to GPT-4o")
    print(f"ü§ñ [AI CALL] Messages: {len(context.messages)}")
    print(f"ü§ñ [AI CALL] Estimated input tokens: ~{estimated_input_tokens}")
    
    # Call the AI
    await next(context)
    
    # Estimate output tokens
    if context.result and hasattr(context.result, 'choices'):
        if hasattr(context.result.choices[0].message, 'content'):
            response_text = str(context.result.choices[0].message.content)
            estimated_output_tokens = len(response_text) // 4
            total_tokens = estimated_input_tokens + estimated_output_tokens
            
            print(f"ü§ñ [AI CALL] Estimated output tokens: ~{estimated_output_tokens}")
            print(f"ü§ñ [AI CALL] Total estimated tokens: ~{total_tokens}")


# ============================================================================
# DEMO TOOLS/FUNCTIONS
# ============================================================================

def get_weather(city: str) -> str:
    """Get current weather for a city."""
    weather_data = {
        "seattle": "‚òÅÔ∏è Cloudy, 15¬∞C, Light drizzle",
        "london": "üåßÔ∏è Rainy, 12¬∞C, Heavy rain",
        "tokyo": "‚òÄÔ∏è Sunny, 22¬∞C, Clear skies",
        "mumbai": "üå§Ô∏è Partly cloudy, 28¬∞C, Humid",
        "paris": "‚õÖ Partly cloudy, 18¬∞C, Mild",
        "new york": "üå®Ô∏è Snowy, -2¬∞C, Light snow",
    }
    return weather_data.get(city.lower(), f"Weather data not available for {city}")


def calculate(expression: str) -> str:
    """Calculate a mathematical expression safely."""
    try:
        # Safe evaluation for basic math
        allowed_names = {}
        result = eval(expression, {"__builtins__": {}}, allowed_names)
        return f"Result: {result}"
    except Exception as e:
        return f"Calculation error: {str(e)}"


def get_time() -> str:
    """Get the current time."""
    return f"Current time: {datetime.now().strftime('%I:%M:%S %p')}"


def search_database(query: str) -> str:
    """Simulate searching a database."""
    # Simulate some processing time
    results = {
        "users": "Found 150 users matching criteria",
        "products": "Found 45 products in inventory",
        "orders": "Found 230 orders in last 30 days",
    }
    return results.get(query.lower(), f"No results found for: {query}")


# ============================================================================
# MAIN INTERACTIVE DEMO
# ============================================================================

async def main():
    print("\n" + "="*75)
    print("üéØ COMPLETE MIDDLEWARE DEMO - All 4 Types Working Together")
    print("="*75)
    
    print("""
This demo shows 4 middleware working simultaneously:

1Ô∏è‚É£  TIMING MIDDLEWARE (Agent)      ‚Üí Tracks how long each request takes
2Ô∏è‚É£  SECURITY MIDDLEWARE (Agent)    ‚Üí Blocks sensitive content
3Ô∏è‚É£  FUNCTION LOGGER (Function)     ‚Üí Logs all tool calls
4Ô∏è‚É£  TOKEN COUNTER (Chat)           ‚Üí Counts tokens sent to AI

Watch how they all work together in a real conversation!
""")
    
    print("="*75)
    print("\nüîß Creating agent with all 4 middleware...\n")
    
    # Create agent with all middleware
    agent = AzureOpenAIChatClient(
        endpoint=ENDPOINT,
        deployment_name=DEPLOYMENT,
        api_key=API_KEY,
        api_version=API_VERSION
    ).create_agent(
        model="gpt-4o",
        instructions="""You are a helpful assistant with access to various tools.
        Be friendly, concise, and helpful in your responses.""",
        tools=[get_weather, calculate, get_time, search_database],
        middleware=[
            timing_middleware,          # Agent middleware #1
            security_middleware,        # Agent middleware #2
            function_logger_middleware, # Function middleware
            token_counter_middleware,   # Chat middleware
        ]
    )
    
    print("‚úÖ Agent created with 4 middleware layers!")
    
    print("\n" + "="*75)
    print("üìù SUGGESTED TEST PROMPTS:")
    print("="*75)
    print("""
To see all middleware in action, try these prompts:

‚úÖ PROMPT 1: "tell me a joke"
   ‚Üí Triggers: Timing + Token Counter
   ‚Üí Simple request, no functions

‚úÖ PROMPT 2: "what's the weather in Tokyo?"
   ‚Üí Triggers: Timing + Function Logger + Token Counter
   ‚Üí Calls the get_weather function

‚úÖ PROMPT 3: "what time is it and calculate 15 * 8"
   ‚Üí Triggers: Timing + Function Logger (2 calls) + Token Counter
   ‚Üí Multiple function calls

‚úÖ PROMPT 4: "what is my password?"
   ‚Üí Triggers: Security (BLOCKS) + Timing
   ‚Üí Security middleware blocks this request!

‚úÖ PROMPT 5: "search for users and get weather in Paris"
   ‚Üí Triggers: ALL 4 middleware
   ‚Üí Multiple functions, shows complete flow

Type 'quit' to exit
""")
    print("="*75 + "\n")
    
    # Get new thread for conversation
    thread = agent.get_new_thread()
    
    # Interactive loop
    while True:
        try:
            user_input = input("üí¨ You: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'bye']:
                print("\nüëã Demo ended! Thanks for testing all the middleware!")
                break
            
            print("\n" + "-"*75)
            print("üîÑ PROCESSING YOUR REQUEST...")
            print("-"*75)
            
            # Stream the response
            print("\nü§ñ Agent: ", end="", flush=True)
            async for chunk in agent.run_stream(user_input, thread=thread):
                print(chunk, end="", flush=True)
            print("\n")
            
            print("-"*75)
            print("‚úÖ Request completed!\n")
            
        except KeyboardInterrupt:
            print("\n\nüëã Demo ended!")
            break
        except Exception as e:
            print(f"\n‚ùå Error: {e}\n")


if __name__ == "__main__":
    asyncio.run(main())
